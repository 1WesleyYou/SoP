\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{parskip}

\setlength{\parskip}{8pt}
% Linespread command allows you to change line spacing for the entire document
\linespread{1.18}

% Tweak page margins
\addtolength{\oddsidemargin}{-.875in}
\addtolength{\evensidemargin}{-.875in}
\addtolength{\textwidth}{1.75in}

\addtolength{\topmargin}{-.875in}
\addtolength{\textheight}{1.75in}

\usepackage{natbib}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{xspace}
\usepackage{fancyhdr}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\newcommand{\Hrule}{\rule{\linewidth}{0.3mm}}

% Project specific macros
\newcommand{\graphite}{GRAPHITE\xspace}
\newcommand{\wave}{WAVE\xspace}

% School specific macros
\newcommand{\schoolShort}{UMD\xspace}
\newcommand{\school}{University of Maryland\xspace}
\newcommand{\schoolLong}{University of Maryland, College Park\xspace}

\newcommand{\profOne}{Prof. Ryan Huang\xspace}
\newcommand{\profTwo}{Prof. Xiaonan Huang\xspace}
\newcommand{\profThree}{Prof. Yutong Ban\xspace}

% Creates header for each page
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\header\hskip\linepagesep\vfootline\thepage}
\newskip\linepagesep \linepagesep 5pt\relax
\def\vfootline{%
    \begingroup
    	\rule[-10pt]{0.75pt}{25pt}
    \endgroup
}
\def\header{%
	\begin{minipage}[]{120pt}
		\hfill Yuchen You
    	\par \hfill 				% Formatting boilerplate
    	CS, PhD, Fall 2026 			% Area, Program, Cycle, Year
    \end{minipage}
}
\fancyhead[RE,LO]{Statement of Purpose | \schoolLong}
\renewcommand\headrulewidth{0pt}

\begin{document}

\textbf{Research Focus and Motivation.}
I am applying to the Computer Science PhD program at the University of Maryland, College Park, to work on \textbf{reliable distributed systems and ML-serving infrastructure}. More concretely, I am interested in how to turn \textbf{noisy, partial telemetry}---metrics, logs, and anomaly alerts---from systems like \textbf{coordination services (e.g., ZooKeeper)} and \textbf{GPU-based inference stacks} into \textbf{SLO-aware diagnoses and mitigation actions} that are practical for real-world operators. My recent work on automated mitigation for ZooKeeper overloads and on launch-bound GPU runtimes has given me hands-on experience building \textbf{measurement pipelines}, \textbf{fault-injection testbeds}, and \textbf{performance-sensitive runtimes}, and has convinced me that we still lack \textbf{abstractions that connect what operators can observe to the reliability guarantees users expect}. I hope to study how the \textbf{operating system}, \textbf{distributed coordination layer}, and \textbf{ML serving stack} can be co-designed around such abstractions so that ML and data services remain within their SLOs despite \textbf{gray failures}~\cite{10.1145/3102980.3103005}, workload shifts, and other latent performance pathologies.

\textbf{Professional Plans and the Role of a PhD.}
In the long term, I hope to build a career as a \textbf{systems researcher} who designs and evaluates \textbf{operating systems} and \textbf{distributed infrastructure for ML and cloud workloads}. Working with such systems has made me aware of the \textbf{operational burden} they impose: even sophisticated cloud stacks demand substantial manual effort to triage noisy alerts, localize performance regressions, and keep ML and data services within their SLOs. This has convinced me that we still lack \textbf{principled ways to connect the telemetry that operators see to the reliability guarantees that cloud users expect}. My ambition is to help develop systems that strengthen the reliability of the ML and data services that many critical applications depend on. Multi-semester systems projects have shown me that I enjoy and can sustain the required time, patience, and focus: weeks spent \textbf{instrumenting systems}, chasing down performance anomalies in noisy telemetry, and iteratively refining runtime mechanisms and experiments. What I now lack, and seek from a PhD, is systematic training in how to \textbf{formulate open research questions}, build \textbf{abstractions that connect mechanisms to reliability guarantees}, and evaluate those abstractions under \textbf{realistic workloads and fault scenarios}, so that I can lead research efforts at the intersection of \textbf{distributed systems, networking, and ML infrastructure}.

\textbf{Learning Reliability from Embedded Robotics.}
Before focusing on large-scale systems, I spent several years in \textbf{embedded systems and robotics}, where I learned that failures often stemmed less from the control law than from unreliable data and weak fault handling. As a research assistant in \textbf{UMich's HDRLab} with \textbf{Prof.~Xiaonan~Huang}, I worked on a \textbf{modular robotic arm platform}, writing low-level firmware and higher-level control code that connected MCUs, sensors, and actuators \textbf{over field buses such as CAN and I\textsuperscript{2}C} and executed model-based dynamics under tight power, bandwidth, and timing constraints. Our project received a \textbf{best-poster award} at an \textbf{ICRA~2025 workshop}~\cite{you2025origami}. In practice, the limiting factor was the data path: noisy, delayed, occasionally corrupted sensor streams meant that naïve controllers could quietly push the arm into unsafe regimes. Adding lightweight monitoring and metrics—simple filtering, sanity checks, and degraded-but-safe modes that fall back to redundant signals or conservative trajectories when data quality drops—made reliability concrete for me and taught me to view robotic and computing systems in terms of \textbf{observability}, \textbf{fault containment}, and \textbf{graceful degradation} under tight budgets, an outlook I now apply to larger-scale distributed and ML systems.

\textbf{Agentic Distributed System Operations.}
At UMich's \textbf{OrderLab} with \textbf{Prof.~Ryan Huang}, I study how to use \textbf{agentic mechanisms} to automate mitigation for overload and gray failures in ZooKeeper clusters. We treat anomaly detectors as given and ask a narrower question: given noisy telemetry and coarse failure signals, can an automated operator choose \textbf{SLO-aware mitigation plans} that are as effective and safe as hand-tuned controllers? To explore this, I helped build an end-to-end platform around a ZooKeeper cluster: \textbf{Prometheus} metrics and alerts, \textbf{HAProxy-based} traffic shaping, a small library of typed mitigation actions (throttling, re-routing, I/O limiting) with safety guards, multi-phase synthetic traffic, and a \textbf{static threshold-based controller baseline}. Experiments showed that this rule-based controller prevents collapse but often \textbf{over-reacts to spikes} or under-reacts to \textbf{slow, correlated degradations}, leaving long windows of elevated p95 latency. I then worked on an \textbf{agentic layer} where an LLM-based planner periodically reads metrics and finite-state summaries and proposes short plans composed only from the constrained mitigation library. An early negative result was that when we briefly exposed a richer API, the planner oscillated between conflicting actions and over-throttled healthy traffic, hurting availability. After tightening the observation and action interfaces and validating plans via replay, we found that the agent consistently \textbf{shortens SLO-violation windows} under gray failures and skewed workloads. This has reinforced my view that ``agentic'' systems only help when grounded in carefully designed \textbf{measurement substrates} and \textbf{guard-railed control surfaces}, a perspective I hope to pursue in PhD work on diagnosable, SLO-aware distributed systems through abstractions that connect telemetry to concrete reliability guarantees.

% PROJECT 3: Graphite - Distributed Temporal Graph Processing
\textbf{CUDA Proxy Player: Runtime Support for Launch-Bound Inference.}
In an \textbf{Advanced Operating Systems} course project, I studied bottlenecks in \textbf{launch-bound GPU inference workloads} such as Mixture-of-Experts serving, hypothesizing that in this regime \textbf{host-side orchestration and kernel launches}, rather than raw FLOPs, dominate end-to-end latency. I co-designed \textbf{CUDA Proxy Player}, a multi-path runtime that \textbf{routes requests by size and shape} to eager, \textbf{persistent-kernel}, or \textbf{CUDA Graph} paths. The runtime then \textbf{glues these execution flows together}, managing graph capture, replay, and kernel scheduling so that we can exploit graphs where they help while avoiding their overhead on tiny requests. I built most of the benchmarking framework---microbenchmarks and graphs over varying expert sizes and batch shapes---and used it to compare these paths under synthetic traffic. In the launch-bound regime, this size-aware routing and glued execution allowed our CUDA Graph path to \textbf{outperform a naive eager baseline}, reducing latency by about \textbf{10\%} in the most launch-bound scenarios. However, our experiments also revealed important limitations of the persistent-kernel path: keeping workers resident, with activation and workspace buffers pinned in GPU VRAM, shrank headroom for co-located high-VRAM jobs and sometimes worsened tail latency under multi-tenant workloads. These tradeoffs have convinced me that GPU runtimes for ML serving should focus less on a single ``fastest'' path and more on exposing the right \textbf{telemetry and control hooks} for VRAM usage, admission control, and path selection.

\textbf{Fit with UMD CS and Prof.~Zaoxing Liu.}
UMD's strength in \textbf{operating systems}, \textbf{networking}, and \textbf{data-intensive computing}, and its cluster of faculty working on systems measurement and reliability, make it an ideal place for the problems I want to work on. Within this environment, I see a particularly strong fit with \textbf{Prof.~Zaoxing~Liu's} work on \textbf{high-fidelity observability and analytics substrates}. My recent projects---a Prometheus-based mitigation and experimentation loop for ZooKeeper and benchmarking frameworks for GPU inference runtimes---have convinced me that reliable distributed and ML systems often lack \emph{telemetry substrates that expose the right high-fidelity signals at the right cost}. Prof.~Liu’s \textbf{OctoSketch}~\cite{295671} is exactly the kind of real-time, multi-core sketching substrate I wished I had while diagnosing gray failures and backlog-induced SLO violations in my ZooKeeper environment, and its co-design of sketch algorithms with a high-performance runtime aligns with the abstractions I hope to pursue for ML-serving and GPU-centric systems, where fail-slow behavior often first appears as subtle anomalies in kernel-level signals.

I also see natural alignment with \textbf{MeshAgent}~\cite{zhou2025meshagent}, Prof.~Liu’s LLM-driven network-operations framework. My ZooKeeper work already explores \textbf{agentic mitigation planning} over a typed mitigation library and noisy Prometheus metrics, and MeshAgent suggests how to make such agents \textbf{reliable and interpretable} by grounding them in structured action spaces and uncertainty-aware telemetry. At UMD, I would be excited to build on these ideas by combining a telemetry substrate like OctoSketch with agentic control loops in the spirit of MeshAgent to tackle \textbf{fail-slow faults} and \textbf{tail-latency anomalies} in distributed coordination services and ML-serving stacks, while engaging with the broader \textbf{systems and networking community} on questions of measurement, runtime design, and reliability.

\bibliographystyle{abbrv} 
\bibliography{paper} 

\end{document}