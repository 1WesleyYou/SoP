@inproceedings{you2025origami,
  author    = {Wang, Jiyang and You, Yuchen and Zhang, Xinqi and Fang, Haobo and Wang, Jiaqi and Huang, Xiaonan},
  title     = {Origami Inspired Soft Robotic Arm: A Modular Platform for Manipulation},
  booktitle = {The International Conference on Robotics and Automation (ICRA) 2025 Workshop},
  year      = {2025},
  month     = may
}

@inproceedings{10.1145/3102980.3103005,
author = {Huang, Peng and Guo, Chuanxiong and Zhou, Lidong and Lorch, Jacob R. and Dang, Yingnong and Chintalapati, Murali and Yao, Randolph},
title = {Gray Failure: The Achilles' Heel of Cloud-Scale Systems},
year = {2017},
isbn = {9781450350686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3102980.3103005},
doi = {10.1145/3102980.3103005},
abstract = {Cloud scale provides the vast resources necessary to replace failed components, but this is useful only if those failures can be detected. For this reason, the major availability breakdowns and performance anomalies we see in cloud environments tend to be caused by subtle underlying faults, i.e., gray failure rather than fail-stop failure. In this paper, we discuss our experiences with gray failure in production cloud-scale systems to show its broad scope and consequences. We also argue that a key feature of gray failure is differential observability: that the system's failure detectors may not notice problems even when applications are afflicted by them. This realization leads us to believe that, to best deal with them, we should focus on bridging the gap between different components' perceptions of what constitutes failure.},
booktitle = {Proceedings of the 16th Workshop on Hot Topics in Operating Systems},
pages = {150–155},
numpages = {6},
location = {Whistler, BC, Canada},
series = {HotOS '17}
}

@inproceedings{dong2025failslow,
  author    = {Gen Dong and
               Yu Hua and
               Yongle Zhang and
               Zhangyu Chen and
               Menglei Chen},
  title     = {Understanding and Detecting Fail-Slow Hardware Failure Bugs in Cloud Systems},
  booktitle = {Proceedings of the 2025 USENIX Annual Technical Conference (USENIX ATC 25)},
  pages     = {1127--1142},
  year      = {2025},
  address   = {Boston, MA, USA},
  month     = jul,
  publisher = {USENIX Association},
  url       = {https://www.usenix.org/conference/atc25/presentation/dong}
}

@inproceedings{10.1145/3600006.3613148,
author = {Gong, Sishuai and Peng, Dinglan and Alt\i{}nb\"{u}ken, Deniz and Fonseca, Pedro and Maniatis, Petros},
title = {Snowcat: Efficient Kernel Concurrency Testing using a Learned Coverage Predictor},
year = {2023},
isbn = {9798400702297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600006.3613148},
doi = {10.1145/3600006.3613148},
abstract = {Random-based approaches and heuristics are commonly used in kernel concurrency testing due to the massive scale of modern kernels and corresponding interleaving space. The lack of accurate and scalable approaches to analyze concurrent kernel executions makes existing testing approaches heavily rely on expensive dynamic executions to measure the effectiveness of a new test. Unfortunately, the high cost incurred by dynamic executions limits the breadth of the exploration and puts latency pressure on finding effective concurrent test inputs and schedules, hindering the overall testing effectiveness.This paper proposes Snowcat, a kernel concurrency testing framework that generates effective test inputs and schedules using a learned kernel block-coverage predictor. Using a graph neural network, the coverage predictor takes a concurrent test input and scheduling hints and outputs a prediction on whether certain important code blocks will be executed. Using this predictor, Snowcat can skip concurrent tests that are likely to be fruitless and prioritize the promising ones for actual dynamic execution.After testing the Linux kernel for over a week, Snowcat finds ~17\% more potential data races, by prioritizing tests of more fruitful schedules than existing work would have chosen. Snowcat can also find effective test inputs that expose new concurrency bugs with higher probability (1.4\texttimes{}~2.6\texttimes{}), or reproduce known bugs more quickly (15\texttimes{}) than state-of-art testing tools. More importantly, Snowcat is shown to be more efficient at reaching a desirable level of race coverage in the continuous setting, as the Linux kernel evolves from version to version. In total, Snowcat discovered 17 new concurrency bugs in Linux kernel 6.1, of which 13 are confirmed and 6 are fixed.},
booktitle = {Proceedings of the 29th Symposium on Operating Systems Principles},
pages = {35–51},
numpages = {17},
keywords = {concurrency programming, software testing and debugging, operating systems security, kernel concurrency bugs},
location = {Koblenz, Germany},
series = {SOSP '23}
}

@inproceedings{10.5555/3767901.3767935,
author = {Zhang, Tianren and Gong, Sishuai and Fonseca, Pedro},
title = {KRR: efficient and scalable kernel record replay},
year = {2025},
isbn = {978-1-939133-47-2},
publisher = {USENIX Association},
address = {USA},
abstract = {Modern kernels are large, complex, and plagued with bugs. Unfortunately, their large size and complexity make kernel failures very challenging for developers to diagnose since failures encountered in deployment are often notoriously difficult to reproduce. Although record-replay techniques provide the powerful ability to accurately record a failed execution and deterministically replay it, enabling advanced manual and automated analysis techniques, they are inefficient and do not scale with modern I/O-intensive, concurrent workloads.This paper introduces KRR, a kernel record-replay framework that provides a highly efficient execution recording mechanism by narrowing the scope of the record and replay boundary to the kernel. Unlike previous record-replay wholestack approaches, KRR adopts a split-recorder design that employs the guest and the host to jointly record the kernel execution. Our evaluation demonstrates that KRR scales efficiently up to 8 cores, across a range of different workloads, including kernel compilation, RocksDB, and Nginx. When recording 8-core VMs that run RocksDB and kernel compilation, KRR incurs only a 1.52\texttimes{} ∼ 2.79\texttimes{} slowdown compared to native execution, while traditional whole-VM RR suffers from 8.97\texttimes{} ∼ 29.94\texttimes{} slowdown. We validate that KRR is practical and has a broad recording scope by reproducing 17 bugs across different Linux versions, including 6 non-deterministic bugs and 5 high-risk CVEs; KRR was able to record and reproduce all but one non-deterministic bug.},
booktitle = {Proceedings of the 19th USENIX Conference on Operating Systems Design and Implementation},
articleno = {34},
numpages = {18},
location = {Boston, MA, USA},
series = {OSDI '25}
}

@inproceedings {211291,
author = {Amin Tootoonchian and Aurojit Panda and Chang Lan and Melvin Walls and Katerina Argyraki and Sylvia Ratnasamy and Scott Shenker},
title = {{ResQ}: Enabling {SLOs} in Network Function Virtualization},
booktitle = {15th USENIX Symposium on Networked Systems Design and Implementation (NSDI 18)},
year = {2018},
isbn = {978-1-939133-01-4},
address = {Renton, WA},
pages = {283--297},
url = {https://www.usenix.org/conference/nsdi18/presentation/tootoonchian},
publisher = {USENIX Association},
month = apr
}

@inproceedings{10.1145/3626111.3628201,
author = {Amaro, Emmanuel and Wang, Stephanie and Panda, Aurojit and Aguilera, Marcos K.},
title = {Logical Memory Pools: Flexible and Local Disaggregated Memory},
year = {2023},
isbn = {9798400704154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626111.3628201},
doi = {10.1145/3626111.3628201},
abstract = {We propose logical memory pools, a memory disaggregation architecture for the emerging Compute Express Link (CXL) technology in datacenters. The key idea is to create a memory pool by carving out parts of the local memory in each server, rather than using a physical memory pool that is separate from servers. Logical pools provide significant benefits over physical pools, namely, lower cost, support for near-memory computing without extra hardware, and flexibility on designating whether memory is part of the memory pool or not. We demonstrate that logical pools can execute workloads that are unfeasible in physical pools, and that its faster access leads to better performance. Realizing logical memory pools poses five major challenges, which we believe can be overcome. Given the benefits of logical pools, we believe the CXL community should refocus efforts on logical, rather than physical memory pools.},
booktitle = {Proceedings of the 22nd ACM Workshop on Hot Topics in Networks},
pages = {25–32},
numpages = {8},
location = {Cambridge, MA, USA},
series = {HotNets '23}
}

@inproceedings{Yu_2025, series={EuroSys ’25},
   title={Stateful Large Language Model Serving with Pensieve},
   url={http://dx.doi.org/10.1145/3689031.3696086},
   DOI={10.1145/3689031.3696086},
   booktitle={Proceedings of the Twentieth European Conference on Computer Systems},
   publisher={ACM},
   author={Yu, Lingfan and Lin, Jinkun and Li, Jinyang},
   year={2025},
   month=mar, pages={144–158},
   collection={EuroSys ’25} }


@misc{lin2025understandingstragglerslargemodel,
      title={Understanding Stragglers in Large Model Training Using What-if Analysis}, 
      author={Jinkun Lin and Ziheng Jiang and Zuquan Song and Sida Zhao and Menghan Yu and Zhanghan Wang and Chenyuan Wang and Zuocheng Shi and Xiang Shi and Wei Jia and Zherui Liu and Shuguang Wang and Haibin Lin and Xin Liu and Aurojit Panda and Jinyang Li},
      year={2025},
      eprint={2505.05713},
      archivePrefix={arXiv},
      primaryClass={cs.DC},
      url={https://arxiv.org/abs/2505.05713}, 
}

@misc{zhao2025clmremovinggpumemory,
      title={CLM: Removing the GPU Memory Barrier for 3D Gaussian Splatting}, 
      author={Hexu Zhao and Xiwen Min and Xiaoteng Liu and Moonjun Gong and Yiming Li and Ang Li and Saining Xie and Jinyang Li and Aurojit Panda},
      year={2025},
      eprint={2511.04951},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2511.04951}, 
}

@inproceedings {306045,
author = {Ding Ding and Zhanghan Wang and Jinyang Li and Aurojit Panda},
title = {Runtime Protocol Refinement Checking for Distributed Protocol Implementations},
booktitle = {22nd USENIX Symposium on Networked Systems Design and Implementation (NSDI 25)},
year = {2025},
isbn = {978-1-939133-46-5},
address = {Philadelphia, PA},
pages = {1305--1326},
url = {https://www.usenix.org/conference/nsdi25/presentation/ding},
publisher = {USENIX Association},
month = apr
}