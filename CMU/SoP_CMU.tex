\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{parskip}

\setlength{\parskip}{10pt}
% Linespread command allows you to change line spacing for the entire document
\linespread{1.18}

% Tweak page margins
\addtolength{\oddsidemargin}{-.875in}
\addtolength{\evensidemargin}{-.875in}
\addtolength{\textwidth}{1.75in}

\addtolength{\topmargin}{-.875in}
\addtolength{\textheight}{1.75in}

\usepackage{natbib}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{xspace}
\usepackage{fancyhdr}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\newcommand{\Hrule}{\rule{\linewidth}{0.3mm}}

% Project specific macros
\newcommand{\graphite}{GRAPHITE\xspace}
\newcommand{\wave}{WAVE\xspace}

% School specific macros
\newcommand{\schoolShort}{CMU\xspace}
\newcommand{\school}{Carnegie Mellon University\xspace}
\newcommand{\schoolLong}{Carnegie Mellon University\xspace}

\newcommand{\profOne}{Prof. Ryan Huang\xspace}
\newcommand{\profTwo}{Prof. Xiaonan Huang\xspace}
\newcommand{\profThree}{Prof. Yutong Ban\xspace}

% Creates header for each page
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\header\hskip\linepagesep\vfootline\thepage}
\newskip\linepagesep \linepagesep 5pt\relax
\def\vfootline{%
    \begingroup
    	\rule[-10pt]{0.75pt}{25pt}
    \endgroup
}
\def\header{%
	\begin{minipage}[]{120pt}
		\hfill Yuchen You
    	\par \hfill 				% Formatting boilerplate
    	MSCS, Fall 2026 			% Area, Program, Cycle, Year
    \end{minipage}
}
\fancyhead[RE,LO]{Statement of Purpose | \schoolLong}
\renewcommand\headrulewidth{0pt}

\begin{document}

I am applying to the PhD program in Computer Science to work on reliable systems at the intersection of operating systems, distributed systems, and ML infrastructure, with a particular interest in why complex production systems fail in subtle ways and how we can make them more predictable, diagnosable, and mitigatable.

\textbf{Professional Plans, Career Goals, and the Role of a PhD:}
Long term, I hope to become a systems researcher who designs robust operating systems and distributed infrastructure that cloud operators can rely on. I am motivated by the gap between sophisticated cloud platforms and the fragility we still see in practice--outages, SLO violations, and gray failures--and my realistic goal is to build well-evaluated systems that improve SLO robustness and make such incidents less frequent. A PhD experience will allow me to move beyond course projects to formulating open research questions, building principled abstractions, and evaluating them under realistic workloads, and to learn how to connect low-level mechanisms with high-level reliability goals so that I can eventually lead research efforts that strengthen real-world cloud infrastructure.

\textbf{Research Interests in Reliable Operating, Distributed, and ML Systems:}  I am especially interested in \textbf{fail-slow} and \textbf{gray failures} in \textbf{large-scale ML training and inference}. As clusters scale to thousands of GPUs, subtle performance pathologies can quietly erode throughput and inflate tail latency without ever causing crashes. I would like to design runtime mechanisms and control planes that treat system metrics and training signals as noisy sensors for such latent failures, and adapt scheduling, checkpointing, or collective communication in response, so that clusters can detect and react before problems become visible outages.

More broadly, I am drawn to \textbf{reliability} and \textbf{efficiency} problems across the stack of systems that support \textbf{modern ML workloads}: from distributed storage and coordination services, to communication and scheduling layers for large-scale training, to runtimes and serving systems for dynamic, launch-bounded inference. Across these topics, a unifying theme is building systems that expose the right abstractions to make complex cloud and ML infrastructure more observable, diagnosable, and controllable in production.

%% Why do you wish to attend graduate school? What would you like to study? Keep it broad, details come-in later
%% Describe 2-3 past projects that might be relevant to your research interests. (10-12 lines per project)
% PROJECT 1: P3 - Distributed Graph Neural Network Training at Scale

\textbf{Learning Reliability from Embedded Systems and Soft Robots:}
Before moving fully into systems research, I spent several years working on embedded systems and robotics, which taught me that failures often stem more from unreliable data and weak fault handling than from the control law itself. As an embedded developer for an autonomous sentry robot in \textbf{RoboMaster} competitions and later a research assistant in \textbf{UMich's HDRLab} advised by \textbf{Prof.~Xiaonan~Huang} on a modular soft robot, I was responsible both for firmware that connected MCUs, sensors, and actuators over CAN and $I^2C$ and for the model-based dynamics and control code that consumed these streams; our HDRLab project received a \textbf{best-poster award} at an \textbf{ICRA 2025 workshop}. In practice, however, the limiting factor was often not the controller design but the quality and robustness of the data path: sensor readings could be noisy, delayed, or intermittently corrupted. To keep the system safe and usable, I designed a small but explicit metrics pipeline with filtering, sanity checks, and guards, and implemented fallbacks to redundant signals or predefined degraded-but-safe modes when data quality dropped or components failed, while tuning control gains and trajectories to remain stable under these degraded conditions. Working under tight power and timing constraints, I had to design controllers that used limited actuation budget efficiently while still enforcing strong safety and fault-tolerance guarantees. These experiences made the notion of reliability very concrete for me and trained me to think in terms of \textbf{observability, fault containment, and graceful degradation}--an outlook I now apply to larger-scale distributed and ML systems and that ultimately motivated me to study similar questions in software distributed infrastructures.

\textbf{Agentic Operations for Failures in Distributed Systems:}
With this perspective, I joined \textbf{UMich's OrderLab} advised by \textbf{Prof.~Ryan~Huang} to work on an ``agentic'' approach to operating ZooKeeper clusters under overload failures and network fluctuations. My primary role has been to design and implement the end-to-end experimental platform: a closed-loop control plane that ingests Prometheus telemetry, uses HAProxy-based traffic shaping, and exposes a library of safe, parameterized mitigation actions (e.g., throttling, re-routing, and I/O limiting). On top of this substrate, I built a \textbf{dedicated load generator} that drives multi-stage traffic lifecycles and a \textbf{static mitigator baseline} that applies simple threshold-based rules, allowing us to quantify recovery behavior in terms of throughput and tail latency. The agentic layer then adds an LLM-based component that periodically summarizes logs and metrics and proposes sequences of mitigations through a narrow, rate-limited interface. In our testbed, the static controller we designed and carefully tuned can already detect and mitigate many overload and crash scenarios quickly, restoring healthy throughput and tail latency in a wide range of cases. However, in more complex and evolving gray-failure settings, the agent is able to use the same signals to synthesize more targeted sequences of mitigation actions with tuned parameters, which shortens the duration of degraded service and improves recovery quality while still respecting the safety guardrails. This project has been my main research training ground in distributed systems, teaching me to reason about failure modes in terms of mitigation effectiveness, to design strong baselines and ablations, and to iteratively refine mechanisms and evaluation methodology with my advisor.

% PROJECT 3: Graphite - Distributed Temporal Graph Processing
\textbf{CUDA Proxy Player: Runtime Support for Launch-Bounded Inference:}
As part of an \textbf{Advanced Operating Systems} course project and a subsequent independent follow-up, I tackled efficiency challenges in serving launch-bounded MoE-style inference workloads. Working with one collaborator, I co-designed the CUDA Proxy Player, a multi-path runtime that can route each request to an eager, CUDA Graph, or persistent-kernel path depending on workload characteristics. Profiling online decoding pipelines revealed dense timelines of sub-100$\mu$s kernels separated by CPU gaps, indicating that the workload was effectively launch-bounded rather than compute-bounded. My main responsibility was to build the benchmarking and evaluation framework: constructing microbenchmarks and compact MoE forward passes that span realistic expert sizes and hidden dimensions, and using them to compare the different execution paths fairly. In this setting, our CUDA Graph implementation matches a hand-tuned fusion baseline while cutting latency by about 24\% versus naive dispatch. Beyond familiarity with CUDA streams, graphs, and persistent kernels, this project taught me how to identify the true bottleneck, design objective experiments, and choose representative real-world cases to highlight the strengths and limits of new runtime mechanisms.

%% Non-research accomplishments (e.g. Grades, Academic Service, Work experience) (10-12 lines)

% Grades

% TA and Academic Service

% Industry
\textbf{Fit with Purdue CS and Prospective Advisors:}  Purdue's strength in building reliable and secure systems software aligns closely with my preparation and research interests in reliable operating, distributed, and ML systems. My work on embedded and soft-robot reliability, ZooKeeper-based agentic operations, and CUDA runtimes has trained me to build instrumentation pipelines, fault-injection testbeds, and performance-sensitive runtimes—skills that match well with Purdue’s focus on making complex software systems observable, diagnosable, and dependable.
I see a particularly strong fit with \textbf{Prof.~Pedro~Fonseca} and \textbf{Prof.~Yongle~Zhang}. Prof. Zhang’s work on production failures, cross-system interaction bugs, and fail-slow hardware failure bugs in cloud systems closely mirrors my interest in gray failures and SLO-driven reliability for ML training clusters; my experience treating ZooKeeper gray failures and backlog spikes as ``sensor readings'' for latent performance faults would allow me to contribute quickly to his group’s efforts on failure detection, diagnosis, and diagnosable system design. Prof. Fonseca’s Reliable and Secure Systems Lab, spanning \textbf{kernel record–replay}, \textbf{kernel concurrency testing} and \textbf{serverless runtime support}, is equally appealing. Building an agentic control plane has given me hands-on experience with fetching metrics, traces and performance debugging system workloads. I would be excited to explore, with Prof. Fonseca, how ideas from KRR, isolation, and serverless checkpointing can be adapted to reproduce and mitigate fail-slow anomalies in ML infrastructure. Together, these groups and Purdue’s broader systems community provide exactly the environment I am looking for to develop a coherent research agenda on reliable, diagnosable systems for modern cloud and ML workloads.
%% Summary (3-4 Lines)

% Add some blank space between text and references
% \vspace{0.125in}

% References

% **NOTE**: There are better ways to manage citations in LaTeX, most notably using a bibTeX. I wanted to have greater control on how citations were spaced and formatted and therefore ended up hardcoding them here. Your mileage may wary!

\end{document}

% That's All Folks.

% Best of luck, you got this! :)