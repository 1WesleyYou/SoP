\documentclass[10pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{parskip}
\usepackage{setspace}

\usepackage{fontspec}
\setmainfont{Arial}

% \setlength{\parskip}{5pt}
\doublespacing
% Linespread command allows you to change line spacing for the entire document
% \linespread{1.18}

% Tweak page margins
\addtolength{\oddsidemargin}{-.875in}
\addtolength{\evensidemargin}{-.875in}
\addtolength{\textwidth}{1.75in}

\addtolength{\topmargin}{-.875in}
\addtolength{\textheight}{1.75in}

\usepackage{natbib}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{xspace}
\usepackage{fancyhdr}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\newcommand{\Hrule}{\rule{\linewidth}{0.3mm}}

% Project specific macros
\newcommand{\graphite}{GRAPHITE\xspace}
\newcommand{\wave}{WAVE\xspace}

% School specific macros
\newcommand{\schoolShort}{Columbia\xspace}
\newcommand{\school}{Columbia University\xspace}
\newcommand{\schoolLong}{Columbia University\xspace}

\newcommand{\profOne}{Prof. Ryan Huang\xspace}
\newcommand{\profTwo}{Prof. Xiaonan Huang\xspace}
\newcommand{\profThree}{Prof. Yutong Ban\xspace}

% Creates header for each page
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\header\hskip\linepagesep\vfootline\thepage}
\newskip\linepagesep \linepagesep 5pt\relax
\def\vfootline{%
    \begingroup
    	\rule[-10pt]{0.75pt}{25pt}
    \endgroup
}
\def\header{%
	\begin{minipage}[]{120pt}
		\hfill Yuchen You
    	\par \hfill 				% Formatting boilerplate
    	CS, PhD, Fall 2026 			% Area, Program, Cycle, Year
    \end{minipage}
}
\fancyhead[RE,LO]{Personal Statement | \schoolLong}
\renewcommand\headrulewidth{0pt}
\usepackage[margin=1in]{geometry}

\begin{document}

\textbf{Research Focus and Motivation.}
I am applying to \textbf{Columbia University’s} PhD program in Computer Science to study how to make large-scale distributed systems and ML serving stacks \emph{reliably operable} under noisy telemetry, partial observability, and real failures. Today, reliability often hinges on operator intuition: engineers interpret imperfect signals, infer failure modes, and apply playbooks that may stabilize one incident but create regressions elsewhere. Through multi-semester systems projects, I became convinced that we need principled \emph{``telemetry-to-action''} abstractions—interfaces that infer SLO-relevant state from imperfect observations and trigger mitigations with explicit safety and stability constraints—so reliability improves systematically rather than by operator heroics. Columbia’s strengths in systems, networking, and data/AI infrastructure make it an ideal place for me to push this direction.

\textbf{Why a PhD and Career Objectives.}
A PhD is the right next step for me because the problems I care about sit at the boundary of measurement, control, and systems design, where progress requires both conceptual clarity and end-to-end engineering. At Columbia, I hope to sharpen these ideas into durable contributions by working in a community that values careful evaluation, open discussion, and systems built under realistic fault models. Long-term, I aim to build a career as a systems researcher—whether in academia or an industrial research lab—designing reliable infrastructure for cloud and ML workloads where tail latency, correctness, and failure containment matter.

\textbf{Reliability Lessons from Embedded Systems.}
Before focusing on large-scale systems, I worked on embedded systems and robotics under \textbf{Prof. Xiaonan Huang}; our modular robotic arm project was selected for a \textbf{Best Poster Spotlight} at an \textbf{ICRA workshop}~\cite{you2025origami}. That experience made reliability concrete: failures often came from noisy or delayed signals and weak fault handling rather than from control laws alone. Simple monitors, sanity checks, and degraded-but-safe modes were often the difference between a system that merely worked in ideal conditions and one that remained usable under stress. This perspective shapes how I approach distributed and ML systems: prioritize observability, fault containment, and graceful degradation.

\textbf{Agentic Distributed System Operations.}
At \textbf{UMich’s OrderLab} with \textbf{Prof.~Ryan Huang}, I study safe automated mitigation for overload and gray failures in ZooKeeper \textbf{using coarse anomaly signals under partial observability}.
Our question is whether an agentic controller can match a hand-tuned rule-based baseline on \emph{aggregate client throughput} and \emph{mean/p95 latency} without inducing oscillation or throttling. To answer this, I built an end-to-end \textbf{ZooKeeper testbed} with Prometheus telemetry, HAProxy traffic shaping, and a constrained library of typed mitigation actions with safety guards, together with a fault-injection and benchmarking harness (\texttt{zkbench}) that supports weighted injections and load-peak scenarios; we run configurations repeatedly to control variance. As a strong baseline, we implemented a \textbf{denoised rule-based controller} that uses \textbf{sliding-window trend checks} to trigger mitigations and executes parameter-tuned actions from a YAML playbook mapping failure modes to mitigations. While this baseline prevents collapse, it often over- or under-reacts to workload shifts, leaving extended tail-latency windows. I then built an \textbf{agentic layer} where an LLM-based planner reads metrics and finite-state summaries and proposes plans from the same constrained mitigation library; early failures under a richer API (conflicting actions and over-throttling) pushed me to tighten observation/action interfaces. To keep actuation \textbf{safe} under coarse signals and uncertain state, we treat the LLM as a \textbf{proposal generator} and gate execution with safety bounds and replay-based validation on recent traces. With these guardrails, the agent shortened SLO-violation windows under gray failures~\cite{10.1145/3102980.3103005} and skewed workloads. More broadly, this experience convinced me that in reliability control loops, the bottleneck is rarely ``smarter decisions'' but \textbf{designing the right state abstractions and guardrails} so decisions remain stable under noisy signals.

\textbf{CUDA Proxy Player: Runtime Support for Launch-Bound Inference.}
In an Advanced Operating Systems project, we studied when conditional GPU inference (e.g., Mixture-of-Experts serving) becomes \emph{launch-bound}, with host-side orchestration dominating end-to-end latency. Based on the idea that \emph{shape-stable} regions can be amortized while \emph{unstable} glue should be isolated, I co-designed \emph{CUDA Proxy Player}: a multi-path runtime that routes requests by size and shape to eager execution, CUDA Graph replay, or persistent-kernel workers, and stitches these paths together with explicit capture/replay and scheduling interfaces. I built the benchmarking framework—microbenchmarks and end-to-end experiments across expert sizes, batch shapes, and traffic mixes—to explain where each path wins and where coordination overhead dominates. This work reinforced my view that ML serving runtimes should expose telemetry and control hooks (e.g., VRAM headroom, admission control, and path selection) so operators can tune policies to deployment constraints rather than chasing a single ``fastest'' path.

\textbf{Why Columbia Engineering?}
Columbia University is the ideal environment for me to transform these experiences into durable contributions. I am specifically interested in working with \textbf{Prof. Ronghui Gu} to bridge the gap between agentic system operations and formal correctness. While developing LLM-based controllers for ZooKeeper, I realized that statistical mitigations often lack rigorous safety guarantees. I was inspired by \textbf{DuoAI}~\cite{280868}, and I aim to explore how its automated invariant inference can be adapted to runtime control planes---using derived invariants not just for static verification, but as dynamic guardrails to ensure autonomous actions are safe by design. Complementing this, I am eager to collaborate with \textbf{Prof. Asaf Cidon} on ML system reliability. His recent work on \textbf{Nazar}~\cite{hao2023monitoringadaptingmlmodels} demonstrates how continuous monitoring can drive effective adaptation, which aligns perfectly with my vision for principled telemetry-to-action interfaces. I hope to apply similar closed-loop adaptation techniques to large-scale ML serving clusters, ensuring that automated mitigations are both precise and robust.


\newpage
\bibliographystyle{abbrv}
\bibliography{paper}

\end{document}

% That's All Folks.

% Best of luck, you got this! :)