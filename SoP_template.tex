\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{parskip}

\setlength{\parskip}{10pt}
% \setlength{\parindent}{10pt}

%  TODO: 注意这里的用词要符合论文风格, 专业名词这些

% Linespread command allows you to change line spacing for the entire document
\linespread{1.18}

% Tweak page margins
\addtolength{\oddsidemargin}{-.875in}
\addtolength{\evensidemargin}{-.875in}
\addtolength{\textwidth}{1.75in}

\addtolength{\topmargin}{-.875in}
\addtolength{\textheight}{1.75in}

\usepackage{natbib}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{xspace}
\usepackage{fancyhdr}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\newcommand{\Hrule}{\rule{\linewidth}{0.3mm}}

% Project specific macros
\newcommand{\graphite}{GRAPHITE\xspace}
\newcommand{\wave}{WAVE\xspace}

% School specific macros
\newcommand{\schoolShort}{SJTU\xspace}
\newcommand{\school}{Shanghai Jiao Tong University\xspace}
\newcommand{\schoolLong}{Shanghai Jiao Tong University\xspace}

\newcommand{\profOne}{Prof. Ryan Huang\xspace}
\newcommand{\profTwo}{Prof. Xiaonan Huang\xspace}
\newcommand{\profThree}{Prof. Yutong Ban\xspace}

% Creates header for each page
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\header\hskip\linepagesep\vfootline\thepage}
\newskip\linepagesep \linepagesep 5pt\relax
\def\vfootline{%
    \begingroup
    	\rule[-10pt]{0.75pt}{25pt}
    \endgroup
}
\def\header{%
	\begin{minipage}[]{120pt}
		\hfill Yuchen You
    	\par \hfill 				% Formatting boilerplate
    	CS, PhD, Fall 2026 			% Area, Program, Cycle, Year
    \end{minipage}
}
\fancyhead[RE,LO]{Statement of Purpose | \schoolLong}
\renewcommand\headrulewidth{0pt}

\begin{document}

%% Why do you wish to attend graduate school? What would you like to study? Keep it broad, details come-in later
I am applying to pursue a PhD in computer science with a focus on building reliable and efficient systems for machine learning workloads. My dual training in control theory and computer systems has taught me to treat distributed and GPU-based infrastructures as resource-constrained dynamical systems rather than black boxes. Through projects ranging from a user-level thread library and a network file system to real-time firmware for an autonomous robotics team, I have worked at multiple layers of the stack, including concurrency control, and fault handling under tight latency budgets. These experiences have made concrete a tension I want to study systematically: as ML models become larger, more dynamic, and placement-sensitive, the supporting systems must still provide high throughput, low tail latency, and predictable failure modes. My goal in graduate school is to design operating and networking abstractions, GPU runtimes, and agent-assisted operational tools that jointly improve the performance and robustness of ML services, and to develop principled ways to use learning-based methods to diagnose and mitigate complex failures in large-scale distributed systems.

%% Describe 2-3 past projects that might be relevant to your research interests. (10-12 lines per project)

% After mastering system fundamentals through course projects like implementing a user-level thread library, I remained unsatisfied with prototype implementations and sought to understand how production-grade systems achieve security and efficiency. I systematically studied the evolution of system architecture: from the structural foundations of THE and Unix to the modularity of Mach, and the synthesis of isolation and performance in virtualization systems like Xune and Dune. This historical perspective led me to a critical insight: the principles of classic system optimization are not obsolete but can be reimagined for the AI era. I realized that techniques like virtualization and proxying could address the bottleneck of modern MoE models, optimizing their launch speeds and stability. Conversely, I recognized that the generality and few-shot learning capabilities of Large Language Models offer a new paradigm for system reliability, enabling us to handle complex, unseen "gray failures" that traditional rule-based methods cannot solve. This theoretical understanding was cemented by my practical experience as the Embedded Lead for a National Champion robotics team. Working with STM32 and FreeRTOS in resource-constrained environments, I struggled with race conditions and priority inversions that frequently crashed our high-level control algorithms. This harsh reality confirmed that sophisticated AI cannot function without a robust substrate, motivating my transition from robotics to researching the intelligent, self-healing system architectures required to bridge this gap.

% PROJECT 1: P3 - Distributed Graph Neural Network Training at Scale

\textbf{Learning Reliability from Embedded Systems and Soft Robots:}  Before moving fully into systems research, I spent several years working on embedded systems and robotics, which repeatedly taught me that failures often come not from the control law itself but from unreliable data and weak fault handling. As an embedded developer for an autonomous RoboMaster platform and later in UMich’s HDRLab on a modular soft robot that received a best-poster award at an ICRA 2025 workshop, I was responsible for the firmware that connected MCUs, sensors, and actuators over CAN and I²C, and for the model-based dynamics code that consumed these streams. In practice, sensor readings were frequently noisy, delayed, or intermittently corrupted by bus contention and calibration drift. To keep the system safe and functional, I implemented a simple but explicit metrics pipeline: round-robin polling of sensor channels, low-pass filtering and sanity checks to smooth noise and suppress spikes, and guards to detect stuck or out-of-range devices. When individual components failed or data quality dropped below a threshold, the controller would fall back to redundant signals when available or switch the robot into predefined degraded but safe modes. I also had to adapt control cycles and actuation limits under tight power and voltage constraints, trading off aggressive maneuvers against thermal and stability margins. These experiences made the notion of “reliability” very concrete for me: even elegant algorithms collapse if the surrounding system cannot detect, isolate, and contain bad data or partial failures. This perspective now shapes how I think about larger-scale distributed and ML systems, where logs, metrics, and model outputs can be just as noisy and where robust behavior depends critically on building the right mechanisms for fault detection, containment, and recovery.

% PROJECT 2: SURGEON - Early-Exit Inference

The same reliability issues I saw with noisy sensors and partial failures in embedded robots also appear in large-scale services, where logs and metrics can be inconsistent, delayed, or simply missing at the worst possible time. To study this in a more controlled setting, I joined the Order Lab at UMich and worked on an ``agentic'' approach to operating ZooKeeper clusters under overload and gray failures. I first engineered a closed-loop control plane for ZooKeeper: integrating Prometheus telemetry with HAProxy-based traffic shaping and Resilience4j-style circuit breaking, and encapsulating mitigation mechanisms—such as tcconfig-based network throttling, HAProxy Runtime API re-routing, and fsync-based I/O control--into a library of atomic, parameterized bash scripts. On top of this substrate, I built a dedicated load injection framework (zkbench) that drives multi-stage traffic lifecycles (warmup → spike → cooldown) and skewed request distributions to recreate unbalanced pressure patterns. A YAML-configured static controller wired to the same atomic script library serves as a strong baseline: it combines a simple detector over Prometheus time series with deterministic mitigation rules, and a closed-loop evaluator correlates injection rates, throughput, and tail latency to quantify recovery behavior. The agentic layer then adds an LLM-based reasoning component (using GPT-4o via the Model Context Protocol) that periodically scans logs and metrics in sliding windows, summarizes salient anomalies, and proposes sequences of atomic actions through this narrow, rate-limited control interface. In experiments on our testbed, the static baseline handled clean crash scenarios well but often failed to react to gradual slowdowns and gray failures induced by overload, whereas the agent was able to identify some of these dynamic patterns and trigger earlier mitigations while staying within the safety envelope enforced by the guardrails. This project taught me to treat LLMs not as magical operators but as noisy, high-level planners that must be constrained by systems mechanisms such as isolation, idempotent actions, and rollback. 

% PROJECT 3: Graphite - Distributed Temporal Graph Processing
Parallel to my work on reliability, I tackled efficiency challenges in serving launch-bounded MoE-style inference workloads. In the CUDA Proxy Player project, we profiled online decoding pipelines and observed dense timelines of sub-100$\mu$s kernels for routing, packing, scattering, and small expert GEMMs, separated by visible CPU gaps—GPUs still had compute headroom, but the workload was effectively launch-bounded rather than compute-bounded. To address this, I built a multi-path CUDA execution proxy that exposes a single InferenceRequest API and internally routes each request to either a baseline eager path, a piecewise CUDA Graph path, or a persistent-kernel path based on batch size, shape stability, and micro-op density. In the proxy mode, a bucketing layer and Graph Manager partition the operator sequence into graph-safe and glue segments, discretize dominant shapes into buckets, and cache executable CUDA Graphs per (segment, bucket, operator template) class; small shape drifts within a bucket trigger lightweight updates, while incompatible changes fall back to eager launches. For glue segments and micro-op-heavy regions, I implemented a device-resident ring buffer and long-lived GPU workers that dequeue compact task descriptors and execute micro-ops (packing, scatters, activations, small GEMMs) entirely on the GPU, avoiding per-op kernel launches. Microbenchmarks on representative expert sizes and micro-op counts confirm that CUDA Graph replay substantially reduces host launch overhead in the small-to-medium regime, and on a realistic but compact MoE forward pass our CUDA Graph implementation matches a hand-tuned fusion baseline while cutting latency by about 24\% versus naïve dispatch; an early hybrid prototype that combines piecewise graphs with persistent workers further improves performance by launching only the top-k experts, with a more systematic apples-to-apples evaluation still in progress. This project has given me hands-on experience with CUDA streams, graph capture and update, persistent kernels, and routing policies, and solidified my interest in GPU runtimes and serving systems for dynamic ML workloads.

%% Non-research accomplishments (e.g. Grades, Academic Service, Work experience) (10-12 lines)

% Grades

% TA and Academic Service

% Industry
My primary research objective is to engineer resilient infrastructure for large-scale ML training, specifically tackling the insidious challenge of 'fail-slow' hardware phenomena. As foundation models scale to thousands of GPUs, the probability of encountering straggler nodes—caused by thermal throttling, network congestion, or silent silicon aging—approaches certainty. Unlike explicit crashes, these fail-slow faults force the entire synchronous cluster to idle, wasting massive amounts of cloud compute resources and delaying model convergence. Drawing from my experience in characterizing gray failures in ZooKeeper, I aim to develop proactive runtime systems that can detect these performance anomalies early in the training lifecycle. Instead of reactive checkpoint recovery, I propose investigating lightweight, in-band telemetry that correlates system metrics (e.g., PCIe throughput) with algorithmic health (e.g., gradient norms) to identify degrading nodes before they cripple the job. My goal is to transform training clusters from fragile, 'all-or-nothing' environments into elastic systems that autonomously isolate fail-slow components, minimizing the economic and temporal costs of large-scale model development
%% Why this school? List professors you would like to work with and why? (10-12 Lines)

%% Summary (3-4 Lines)

% Add some blank space between text and references
% \vspace{0.125in}

% References

% **NOTE**: There are better ways to manage citations in LaTeX, most notably using a bibTeX. I wanted to have greater control on how citations were spaced and formatted and therefore ended up hardcoding them here. Your mileage may wary!

\end{document}

% That's All Folks.

% Best of luck, you got this! :)