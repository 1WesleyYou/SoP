\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{parskip}

\setlength{\parskip}{10pt}
% Linespread command allows you to change line spacing for the entire document
\linespread{1.18}

% Tweak page margins
\addtolength{\oddsidemargin}{-.875in}
\addtolength{\evensidemargin}{-.875in}
\addtolength{\textwidth}{1.75in}

\addtolength{\topmargin}{-.875in}
\addtolength{\textheight}{1.75in}

\usepackage{natbib}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{xspace}
\usepackage{fancyhdr}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\newcommand{\Hrule}{\rule{\linewidth}{0.3mm}}

% Project specific macros
\newcommand{\graphite}{GRAPHITE\xspace}
\newcommand{\wave}{WAVE\xspace}

% School specific macros
\newcommand{\schoolShort}{UCSD\xspace}
\newcommand{\school}{UC San Diego\xspace}
\newcommand{\schoolLong}{University of California San Diego\xspace}

\newcommand{\profOne}{Prof. Ryan Huang\xspace}
\newcommand{\profTwo}{Prof. Xiaonan Huang\xspace}
\newcommand{\profThree}{Prof. Yutong Ban\xspace}

% Creates header for each page
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\header\hskip\linepagesep\vfootline\thepage}
\newskip\linepagesep \linepagesep 5pt\relax
\def\vfootline{%
    \begingroup
    	\rule[-10pt]{0.75pt}{25pt}
    \endgroup
}
\def\header{%
	\begin{minipage}[]{120pt}
		\hfill Yuchen You
    	\par \hfill 				% Formatting boilerplate
    	CS, PhD, Fall 2026 			% Area, Program, Cycle, Year
    \end{minipage}
}
\fancyhead[RE,LO]{Statement of Purpose | \schoolLong}
\renewcommand\headrulewidth{0pt}

\begin{document}

\paragraph{Research Focus and Motivation.}
I am applying to the Computer Science PhD program at \school{} to study \textbf{reliability for distributed systems and ML serving} by building \textbf{telemetry-to-action} mechanisms: given noisy, partial signals (metrics, logs, traces, and alerts), my goal is to infer SLO-relevant system state and trigger mitigations that are \textbf{safe by construction} (e.g., stability and “never-worsen” constraints). My recent work on ZooKeeper overload mitigation and launch-bound GPU runtimes convinced me that today's stacks still expose telemetry and knobs without a principled interface for \emph{when} and \emph{how} to act---leaving reliability dependent on manual interpretation and ad hoc playbooks.

\paragraph{Professional Plans and the Role of a PhD.}
In the long term, I aim to become a \textbf{systems researcher} who designs and evaluates \textbf{reliable infrastructure for ML and cloud workloads}, where correctness and latency behavior matter under real failures and multi-tenancy. A PhD is essential training to turn this direction into durable contributions: to formulate sharp research questions, develop abstractions that couple observability with control under explicit safety constraints, and validate them through rigorous experimentation and realistic fault models---so reliability improves systematically rather than by operator heroics.

\paragraph{Reliability Lessons from Embedded Systems.}
Before focusing on large-scale systems, advised by \textbf{Prof.~Xiaonan~Huang}, I worked on embedded and robotics; our modular robotic arm project was selected for a \textbf{Best Poster Award} at an \textbf{ICRA workshop}~\cite{you2025origami}. That experience made reliability concrete: failures often came from noisy or delayed signals and weak fault handling rather than from control laws alone. Simple monitors, sanity checks, and degraded-but-safe modes were often the difference between a system that merely worked in ideal conditions and one that remained usable under stress. This perspective now shapes how I approach distributed and ML systems: prioritize observability, fault containment, and graceful degradation.

\paragraph{Agentic Distributed System Operations.}
At \textbf{UMich's OrderLab} with \textbf{Prof.~Ryan Huang}, I study safe automated mitigation for overload and gray failures~\cite{10.1145/3102980.3103005} in ZooKeeper under partial observability. We observe only coarse aggregate metrics/alerts and treat fine-grained causes as latent. Our question is whether an agentic controller can match a hand-tuned rule-based baseline on \emph{aggregate client throughput} and \emph{average and p95 latency} without inducing oscillation or throttling. To answer this, I built an end-to-end \textbf{ZooKeeper testbed} with Prometheus telemetry, HAProxy traffic shaping, and a constrained library of typed mitigation actions with safety guards, together with a fault-injection and benchmarking harness (\texttt{zkbench}) that supports weighted injections and load-peak scenarios; we run configurations repeatedly to control variance. As a strong baseline, we implemented a \textbf{denoised rule-based baseline} that uses \textbf{sliding-window trend checks} to trigger mitigations and executes parameter-tuned mitigations from a YAML playbook mapping failure modes to actions. While this baseline prevents collapse, it often over- or under-reacts to workload shifts, leaving extended tail-latency windows. I then built an \textbf{agentic layer} where an LLM-based planner reads metrics and finite-state summaries and proposes detailed plans from the same constrained mitigation library; early failures under a richer API (conflicting actions and over-throttling) pushed me to tighten observation/action interfaces. To keep actuation \textbf{safe} under coarse signals and uncertain system state, we treat the LLM as a \textbf{proposal generator} and gate execution with safety bounds and replay-based validation on recent traces. With these guardrails, the agent consistently shortened SLO-violation windows under gray failures and skewed workloads. More broadly, this experience convinced me that in reliability control loops, the bottleneck is rarely ``smarter decisions'' but \textbf{designing the right state abstractions and guardrails} so decisions remain stable under noisy signals. Looking ahead, I hope to expand our failure models to stress more complex scenarios and to improve performance by refining mitigation policies while preserving these guardrails.

\paragraph{CUDA Proxy Player: Runtime Support for Launch-Bound Inference.}
In an Advanced Operating Systems course project, we asked when conditional GPU inference (e.g., Mixture-of-Experts serving) truly becomes \emph{launch-bound}, with host-side orchestration dominating end-to-end latency. Based on the hypothesis that \emph{shape-stable} regions can be amortized while \emph{unstable} glue should be isolated, I co-designed CUDA Proxy Player: a multi-path runtime that routes requests by size and shape to eager, CUDA Graph replay, or persistent-kernel execution, and stitches these flows together via explicit capture/replay and scheduling interfaces. I built the benchmarking framework---microbenchmarks and end-to-end experiments spanning expert sizes, batch shapes, and traffic mixes---to quantify where each path wins and why. In the most launch-bound regimes, size-aware routing enabled the CUDA Graph path to deliver substantial gains over a naïve eager baseline; however, our breakdown also showed why a hybrid graph+worker design often fails to translate into end-to-end wins: coordination overheads (worker scheduling and phase barriers) can dominate, and keeping workers/buffers resident reduces VRAM headroom and can worsen tail latency under multi-tenant workloads. Designing these experiments taught me to separate real speedups from coordination artifacts, and reinforced my view that ML serving runtimes should expose telemetry and control hooks---for VRAM usage, admission control, and path selection---so operators can tune policies to deployment constraints rather than chasing a single ``fastest'' path.

\paragraph{Fit with UCSD CSE.}
UC San Diego's strengths in systems and ML infrastructure align closely with my goal of building
\textbf{telemetry-to-action} mechanisms that make large-scale services both efficient and dependable under
realistic failures. I am particularly excited about \textbf{Yufei Ding}'s recent work on agentic LLM workflows,
including \textbf{KVFlow}~\cite{pan2025kvflowefficientprefixcaching}, which models multi-agent execution as an \textbf{Agent Step Graph} to drive
workflow-aware KV-cache eviction and overlapped prefetching that reduce cache-miss recomputation.
Building on both my \textbf{CUDA Proxy Player} experience---where runtime capture and scheduling interfaces
shaped predictability under interference---and my \textbf{agentic distributed-systems ops} work---where I closed
the loop from noisy telemetry to guarded mitigations---I want to develop \textbf{SLO-aware control planes} for
agentic serving that enforce \textbf{stability}/\textbf{``never-worsen'' guardrails} under bursty demand. I am also drawn
to \textbf{Yiying Zhang}'s work on distributed LLM serving, especially \textbf{Preble}~\cite{srivatsa2024prebleefficientdistributedprompt}, which co-optimizes
\textbf{KV-state reuse} and \textbf{load balancing} via \textbf{hierarchical prompt scheduling} to substantially improve
\textbf{tail latency} on real workloads. My experience building \textbf{end-to-end testbeds} and evaluating
\textbf{closed-loop mitigations} under controlled overload and gray-failure scenarios would help strengthen
Preble-style schedulers with \textbf{robustness-oriented evaluation} and \textbf{guardrail-driven adaptation} under
noisy, bursty traffic.

\bibliographystyle{abbrv}
\bibliography{paper}

\end{document}