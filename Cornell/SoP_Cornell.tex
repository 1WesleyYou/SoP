\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{parskip}

\setlength{\parskip}{8pt}
% Linespread command allows you to change line spacing for the entire document
% Please use the Academic Statement of Purpose to describe (within 1000 words) the substantive research questions you are interested in pursuing during your graduate studies, and explain how our program would help you achieve your intellectual goals. Additionally, detail your academic background, intellectual interests, and any training or research experience you have received that you believe has prepared you for our program. Within your statement, please also identify specific faculty members whose research interests align with your own interests.
% 请使用学术陈述目的来描述（在 1000 字以内）您在研究生学习期间感兴趣的研究问题，并解释我们的项目将如何帮助您实现您的学术目标。此外，请详细说明您的学术背景、学术兴趣，以及您所接受的任何培训或研究经验，这些您认为使您为我们的项目做好了准备。在您的陈述中，请还指明具体哪些教师的研究兴趣与您自己的兴趣相一致。
\linespread{1.58}

% Tweak page margins
\addtolength{\oddsidemargin}{-.875in}
\addtolength{\evensidemargin}{-.875in}
\addtolength{\textwidth}{1.75in}

\addtolength{\topmargin}{-.875in}
\addtolength{\textheight}{1.75in}

\usepackage{natbib}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{xspace}
\usepackage{fancyhdr}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\newcommand{\Hrule}{\rule{\linewidth}{0.3mm}}

% Project specific macros
\newcommand{\graphite}{GRAPHITE\xspace}
\newcommand{\wave}{WAVE\xspace}

% School specific macros
\newcommand{\schoolShort}{Cornell\xspace}
\newcommand{\school}{Cornell University\xspace}
\newcommand{\schoolLong}{Cornell University\xspace}

\newcommand{\profOne}{Prof. Ryan Huang\xspace}
\newcommand{\profTwo}{Prof. Xiaonan Huang\xspace}
\newcommand{\profThree}{Prof. Yutong Ban\xspace}

% Creates header for each page
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\header\hskip\linepagesep\vfootline\thepage}
\newskip\linepagesep \linepagesep 5pt\relax
\def\vfootline{%
    \begingroup
    	\rule[-10pt]{0.75pt}{25pt}
    \endgroup
}
\def\header{%
	\begin{minipage}[]{120pt}
		\hfill Yuchen You
    	\par \hfill 				% Formatting boilerplate
    	CS, PhD, Fall 2026 			% Area, Program, Cycle, Year
    \end{minipage}
}
\fancyhead[RE,LO]{Statement of Purpose | \schoolLong}
\renewcommand\headrulewidth{0pt}

\begin{document}

\paragraph{Research Focus and Motivation.}
I am applying to the Computer Science PhD program at \school{} to study \textbf{reliability for distributed systems and ML serving} by building \textbf{telemetry-to-action} mechanisms: given noisy, partial signals (metrics, logs, traces, and alerts), my goal is to infer SLO-relevant system state and trigger mitigations that are \textbf{safe by construction} (e.g., stability and “never-worsen” constraints). My recent work on ZooKeeper overload mitigation and launch-bound GPU runtimes convinced me that today's stacks still expose telemetry and knobs without a principled interface for \emph{when} and \emph{how} to act---leaving reliability dependent on manual interpretation and ad hoc playbooks.

\paragraph{Professional Plans and the Role of a PhD.}
In the long term, I aim to become a \textbf{systems researcher} who designs and evaluates \textbf{reliable infrastructure for ML and cloud workloads}, where correctness and latency behavior matter under real failures and multi-tenancy. A PhD is essential training to turn this direction into durable contributions: to formulate sharp research questions, develop abstractions that couple observability with control under explicit safety constraints, and validate them through rigorous experimentation and realistic fault models---so reliability improves systematically rather than by operator heroics.

\paragraph{Reliability Lessons from Embedded Systems.}
Before focusing on large-scale systems, advised by \textbf{Prof.~Xiaonan~Huang}, I worked on embedded and robotics; our modular robotic arm project was selected for a \textbf{Best Poster Spotlight} at an \textbf{ICRA workshop}~\cite{you2025origami}. That experience made reliability concrete: failures often came from noisy or delayed signals and weak fault handling rather than from control laws alone. Simple monitors, sanity checks, and degraded-but-safe modes were often the difference between a system that merely worked in ideal conditions and one that remained usable under stress. This perspective now shapes how I approach distributed and ML systems: prioritize observability, fault containment, and graceful degradation.

\paragraph{Agentic Distributed System Operations.}
At \textbf{UMich's OrderLab} with \textbf{Prof.~Ryan Huang}, I study safe automated mitigation for overload and gray~\cite{10.1145/3102980.3103005} failures in ZooKeeper under partial observability. We observe only coarse aggregate metrics/alerts and treat fine-grained causes as latent. Our question is whether an agentic controller can match a hand-tuned rule-based baseline on \emph{aggregate client throughput} and \emph{average and p95 latency} without inducing oscillation or throttling. To answer this, I built an end-to-end \textbf{ZooKeeper testbed} with Prometheus telemetry, HAProxy traffic shaping, and a constrained library of typed mitigation actions with safety guards, together with a fault-injection and benchmarking harness (\texttt{zkbench}) that supports weighted injections and load-peak scenarios; we run configurations repeatedly to control variance. As a strong baseline, we implemented a \textbf{denoised rule-based baseline} that uses \textbf{sliding-window trend checks} to trigger mitigations and executes parameter-tuned mitigations from a YAML playbook mapping failure modes to actions. While this baseline prevents collapse, it often over- or under-reacts to workload shifts, leaving extended tail-latency windows. I then built an \textbf{agentic layer} where an LLM-based planner reads metrics and finite-state summaries and proposes detailed plans from the same constrained mitigation library; early failures under a richer API (conflicting actions and over-throttling) pushed me to tighten observation/action interfaces. To keep actuation \textbf{safe} under coarse signals and uncertain system state, we treat the LLM as a \textbf{proposal generator} and gate execution with safety bounds and replay-based validation on recent traces. With these guardrails, the agent consistently shortened SLO-violation windows under gray failures and skewed workloads. More broadly, this experience convinced me that in reliability control loops, the bottleneck is rarely ``smarter decisions'' but \textbf{designing the right state abstractions and guardrails} so decisions remain stable under noisy signals. Looking ahead, I hope to expand our failure models to stress more complex scenarios and to improve performance by refining mitigation policies while preserving these guardrails.

\paragraph{CUDA Proxy Player: Runtime Support for Launch-Bound Inference.}
In an Advanced Operating Systems course project, we asked when conditional GPU inference (e.g., Mixture-of-Experts serving) truly becomes \emph{launch-bound}, with host-side orchestration dominating end-to-end latency. Based on the hypothesis that \emph{shape-stable} regions can be amortized while \emph{unstable} glue should be isolated, I co-designed CUDA Proxy Player: a multi-path runtime that routes requests by size and shape to eager, CUDA Graph replay, or persistent-kernel execution, and stitches these flows together via explicit capture/replay and scheduling interfaces. I built the benchmarking framework---microbenchmarks and end-to-end experiments spanning expert sizes, batch shapes, and traffic mixes---to quantify where each path wins and why. In the most launch-bound regimes, size-aware routing enabled the CUDA Graph path to deliver substantial gains over a naïve eager baseline; however, our breakdown also showed why a hybrid graph+worker design often fails to translate into end-to-end wins: coordination overheads (worker scheduling and phase barriers) can dominate, and keeping workers/buffers resident reduces VRAM headroom and can worsen tail latency under multi-tenant workloads. Designing these experiments taught me to separate real speedups from coordination artifacts, and reinforced my view that ML serving runtimes should expose telemetry and control hooks---for VRAM usage, admission control, and path selection---so operators can tune policies to deployment constraints rather than chasing a single ``fastest'' path.

\textbf{Fit with Cornell CS, Prof.~Hakim~Weatherspoon, and Prof.~Jiaxin~Lin.}
Cornell's systems and networking strengths, and CSL's CS--ECE environment, align with my goal of reliable infrastructure for ML and data-intensive services. I am excited by \textbf{Prof.~Hakim~Weatherspoon}'s \textbf{Shale}~\cite{10.1145/3651890.3672248} on reconfigurable networks and how fabric policies shape tail latency and robustness. My ZooKeeper/HDFS agentic-ops work closes the loop from Prometheus telemetry to guarded HAProxy/\texttt{tc} mitigations, and I hope to apply similar telemetry-to-action control at the fabric layer.

I am also drawn to \textbf{Prof.~Jiaxin~Lin}'s \textbf{RingLeader}~\cite{286477}, which offloads intra-server orchestration to programmable NICs. In \emph{CUDA Proxy Player}, I reduced MoE inference latency by routing requests across eager, persistent-kernel, and CUDA Graph paths. At Cornell, I hope to build \textbf{network- and NIC-aware distributed systems} where reliability is grounded in fabric/NIC behavior and ML tail-latency needs.
%% Summary (3-4 Lines)

% Add some blank space between text and references
% \vspace{0.125in}

% References

% **NOTE**: There are better ways to manage citations in LaTeX, most notably using a bibTeX. I wanted to have greater control on how citations were spaced and formatted and therefore ended up hardcoding them here. Your mileage may wary!

\bibliographystyle{abbrv}
\bibliography{paper}

\end{document}

% That's All Folks.

% Best of luck, you got this! :)