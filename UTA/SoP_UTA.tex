\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{parskip}

\setlength{\parskip}{8pt}
% Linespread command allows you to change line spacing for the entire document
\linespread{1.2}

% Tweak page margins
\addtolength{\oddsidemargin}{-.875in}
\addtolength{\evensidemargin}{-.875in}
\addtolength{\textwidth}{1.75in}

\addtolength{\topmargin}{-.875in}
\addtolength{\textheight}{1.75in}

\usepackage{natbib}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{xspace}
\usepackage{fancyhdr}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\newcommand{\Hrule}{\rule{\linewidth}{0.3mm}}

% Project specific macros
\newcommand{\graphite}{GRAPHITE\xspace}
\newcommand{\wave}{WAVE\xspace}

% School specific macros
\newcommand{\schoolShort}{UT Austin\xspace}
\newcommand{\school}{University of Texas at Austin\xspace}
\newcommand{\schoolLong}{University of Texas at Austin\xspace}

\newcommand{\profOne}{Prof. Ryan Huang\xspace}
\newcommand{\profTwo}{Prof. Xiaonan Huang\xspace}
\newcommand{\profThree}{Prof. Yutong Ban\xspace}

% Creates header for each page
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\header\hskip\linepagesep\vfootline\thepage}
\newskip\linepagesep \linepagesep 5pt\relax
\def\vfootline{%
    \begingroup
    	\rule[-10pt]{0.75pt}{25pt}
    \endgroup
}
\def\header{%
	\begin{minipage}[]{120pt}
		\hfill Yuchen You
    	\par \hfill 				% Formatting boilerplate
    	CS, PhD, Fall 2026 			% Area, Program, Cycle, Year
    \end{minipage}
}
\fancyhead[RE,LO]{Statement of Purpose | \schoolLong}
\renewcommand\headrulewidth{0pt}

\begin{document}

\paragraph{Research Focus and Motivation.}
I am applying to the Computer Science PhD program at the \school{} to study \textbf{reliability for distributed systems and ML serving} by building \textbf{telemetry-to-action} mechanisms: given noisy, partial signals (metrics, logs, traces, and alerts), my goal is to infer SLO-relevant system state and trigger mitigations that are \textbf{safe by construction} (e.g., stability and “never-worsen” constraints). My recent work on ZooKeeper overload mitigation and launch-bound GPU runtimes convinced me that today's stacks still expose telemetry and knobs without a principled interface for \emph{when} and \emph{how} to act---leaving reliability dependent on manual interpretation and ad hoc playbooks.

\paragraph{Professional Plans and the Role of a PhD.}
In the long term, I aim to become a \textbf{systems researcher} who designs and evaluates \textbf{reliable infrastructure for ML and cloud workloads}, where correctness and latency behavior matter under real failures and multi-tenancy. A PhD is essential training to turn this direction into durable contributions: to formulate sharp research questions, develop abstractions that couple observability with control under explicit safety constraints, and validate them through rigorous experimentation and realistic fault models---so reliability improves systematically rather than by operator heroics.

\paragraph{Reliability Lessons from Embedded Systems.}
Before focusing on large-scale systems, I worked on embedded systems and robotics under \textbf{Prof.~Xiaonan~Huang}; our modular robotic arm project was selected for a \textbf{Best Poster Award} at an \textbf{ICRA workshop}~\cite{you2025origami}. That experience made reliability concrete: failures often came from noisy or delayed signals and weak fault handling rather than from control laws alone. Simple monitors, sanity checks, and degraded-but-safe modes were often the difference between a system that merely worked in ideal conditions and one that remained usable under stress. This perspective now shapes how I approach distributed and ML systems: prioritize observability, fault containment, and graceful degradation.

\paragraph{Agentic Distributed System Operations.}
At \textbf{UMich's OrderLab} with \textbf{Prof.~Ryan Huang}, I study safe automated mitigation for overload and gray failures~\cite{10.1145/3102980.3103005} in ZooKeeper under partial observability. We observe only coarse aggregate metrics/alerts and treat fine-grained causes as latent. Our question is whether an agentic controller can match a hand-tuned rule-based baseline on \emph{aggregate client throughput} and \emph{mean and p95 latency} without inducing oscillation or throttling. To answer this, I built an end-to-end \textbf{ZooKeeper testbed} with Prometheus telemetry, HAProxy traffic shaping, and a constrained library of typed mitigation actions with safety guards, together with a fault-injection and benchmarking harness (\texttt{zkbench}) that supports weighted injections and load-peak scenarios; we run configurations repeatedly to control variance. As a strong comparison point, we implemented a \textbf{denoised rule-based baseline} that uses \textbf{sliding-window trend checks} to trigger mitigations and executes parameter-tuned mitigations from a YAML playbook mapping failure modes to actions. While this baseline prevents collapse, it often over- or under-reacts to workload shifts, leaving extended tail-latency windows. I then built an \textbf{agentic layer} where an LLM-based planner reads metrics and finite-state summaries and proposes detailed plans from the same constrained mitigation library; early failures under a richer API (conflicting actions and over-throttling) pushed me to tighten observation/action interfaces. To keep actuation \textbf{safe} under coarse signals and uncertain system state, we treat the LLM as a \textbf{proposal generator} and gate execution with safety bounds and replay-based validation on recent traces. With these guardrails, the agent consistently reduced the SLO-violation windows under gray failures and skewed workloads. More broadly, this experience convinced me that in reliability control loops, the bottleneck is rarely ``smarter decisions'' but \textbf{designing the right state abstractions and guardrails} so decisions remain stable under noisy signals. Looking ahead, I hope to expand our failure models to stress more complex scenarios and to improve performance by refining mitigation policies while preserving these guardrails.

\paragraph{CUDA Proxy Player: Runtime Support for Launch-Bound Inference.}
In an Advanced Operating Systems course project, we asked when conditional GPU inference (e.g., Mixture-of-Experts serving) truly becomes \emph{launch-bound}, with host-side orchestration dominating end-to-end latency. Based on the hypothesis that \emph{shape-stable} regions can be amortized while \emph{unstable} glue should be isolated, I co-designed CUDA Proxy Player: a multi-path runtime that routes requests by size and shape to eager, CUDA Graph replay, or persistent-kernel execution, and stitches these flows together via explicit capture/replay and scheduling interfaces. I built the benchmarking framework---microbenchmarks and end-to-end experiments spanning expert sizes, batch shapes, and traffic mixes---to quantify where each path wins and why. In the most launch-bound regimes, size-aware routing enabled the CUDA Graph path to deliver substantial gains over a naïve eager baseline; however, our breakdown also showed why a hybrid graph+worker design often fails to translate into end-to-end wins: coordination overheads (worker scheduling and phase barriers) can dominate, and keeping workers/buffers resident reduces VRAM headroom and can worsen tail latency under multi-tenant workloads. Designing these experiments taught me to separate real speedups from coordination artifacts, and reinforced my view that ML serving runtimes should expose telemetry and control hooks---for VRAM usage, admission control, and path selection---so operators can tune policies to deployment constraints rather than chasing a single ``fastest'' path.

% Industry
\paragraph{Fit with \schoolShort{} Computer Science.}
\schoolShort{}'s strengths in systems and networking align closely with my goal of building
\textbf{telemetry-to-action} mechanisms that make large-scale services both \textbf{efficient} and
\textbf{dependable} under realistic failures. I am particularly excited about
\textbf{Prof.~Vijay~Chidambaram}'s \textbf{SquirrelFS}~\cite{298707}, which uses Rust \textbf{typestate} to make
file-system crash safety \textbf{checkable by construction}, enforcing crash-safe \textbf{update ordering}
at compile time. Building on my agentic distributed-systems ops work---where I closed the loop from noisy
telemetry to \textbf{guarded mitigations}---I want to translate SquirrelFS-style constraints into
\textbf{runtime guardrails} for autonomous recovery (i.e., \textbf{admitting} actions only when preconditions hold) and
validate them under systematic \textbf{fault injection} and gray failures.
I am also drawn to \textbf{Prof.~Venkat~Arun}'s work on \textbf{CCAC}~\cite{10.1145/3452296.3472912}, which formalizes and checks
congestion-control behaviors against specifications to surface subtle safety and performance pathologies.
My experience building end-to-end testbeds and robustness-oriented evaluations would help strengthen this
direction by connecting specification-driven checks to a \textbf{never-worsen safety envelope} and
counterexample-driven refinement under noisy, bursty traffic.

\bibliographystyle{abbrv}
\bibliography{paper}

\end{document}

% That's All Folks.

% Best of luck, you got this! :)