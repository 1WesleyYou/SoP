\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{parskip}
\usepackage{setspace}

\setlength{\parskip}{10pt}
% \doublespacing
% Linespread command allows you to change line spacing for the entire document
\linespread{1.5}

% Tweak page margins
\addtolength{\oddsidemargin}{-.875in}
\addtolength{\evensidemargin}{-.875in}
\addtolength{\textwidth}{1.75in}

\addtolength{\topmargin}{-.875in}
\addtolength{\textheight}{1.75in}

\usepackage{natbib}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{xspace}
\usepackage{fancyhdr}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\newcommand{\Hrule}{\rule{\linewidth}{0.3mm}}

% Project specific macros
\newcommand{\graphite}{GRAPHITE\xspace}
\newcommand{\wave}{WAVE\xspace}

% School specific macros
\newcommand{\schoolShort}{Harvard\xspace}
\newcommand{\school}{Harvard University\xspace}
\newcommand{\schoolLong}{Harvard University\xspace}

\newcommand{\profOne}{Prof. Ryan Huang\xspace}
\newcommand{\profTwo}{Prof. Xiaonan Huang\xspace}
\newcommand{\profThree}{Prof. Yutong Ban\xspace}

% Creates header for each page
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\header\hskip\linepagesep\vfootline\thepage}
\newskip\linepagesep \linepagesep 5pt\relax
\def\vfootline{%
    \begingroup
    	\rule[-10pt]{0.75pt}{25pt}
    \endgroup
}
\def\header{%
	\begin{minipage}[]{120pt}
		\hfill Yuchen You
    	\par \hfill 				% Formatting boilerplate
    	CS, PhD, Fall 2026 			% Area, Program, Cycle, Year
    \end{minipage}
}
\fancyhead[RE,LO]{Statement of Purpose | \schoolLong}
\renewcommand\headrulewidth{0pt}

\begin{document}

% --- SOP Body (<= 1000 words), bold lead for every paragraph ---

\textbf{Research Focus and Motivation.}
I am applying to Harvard’s PhD program in Computer Science to study how to make large-scale distributed and ML-serving systems \emph{reliably operable} under noisy telemetry, partial observability, and real failures. Modern services often depend on operator intuition: engineers interpret imperfect metrics, infer failure modes, and apply playbooks that may stabilize one incident but create regressions elsewhere. Through multi-semester systems projects, I became convinced that we need principled ``telemetry-to-action'' abstractions---interfaces that infer SLO-relevant state from imperfect signals and trigger mitigations with explicit safety and stability constraints---so reliability improves systematically rather than by operator heroics.

\textbf{Why a PhD and Career Objectives.}
Pursuing a PhD is the right next step for me because the problems I care about sit at the boundary of measurement, control, and systems design. I want rigorous training to (1) formulate sharp research questions about operating under uncertainty, (2) design mechanisms whose safety properties are explicit and testable, and (3) validate them through careful experimentation with realistic fault models and reproducible benchmarks. Long-term, I aim to build a career as a systems researcher---whether in academia or an industrial research lab---designing reliable infrastructure for cloud and ML workloads where tail latency, correctness, and failure containment matter.

\paragraph{Reliability Lessons from Embedded Systems.}
Before focusing on large-scale systems, advised by \textbf{Prof.~Xiaonan~Huang}, I worked on embedded and robotics; our modular robotic arm project was selected for a \textbf{Best Poster Spotlight} at an \textbf{ICRA workshop}~\cite{you2025origami}. That experience made reliability concrete: failures often came from noisy or delayed signals and weak fault handling rather than from control laws alone. Simple monitors, sanity checks, and degraded-but-safe modes were often the difference between a system that merely worked in ideal conditions and one that remained usable under stress. This perspective now shapes how I approach distributed and ML systems: prioritize observability, fault containment, and graceful degradation.

\paragraph{Agentic Distributed System Operations.}
At \textbf{UMich’s OrderLab} with \textbf{Prof.~Ryan Huang}, I study safe automated mitigation for overload and gray failures in ZooKeeper \textbf{from coarse anomaly signals under partial observability}.
Our question is whether an agentic controller can match a hand-tuned rule-based baseline on \emph{aggregate client throughput} and \emph{average and p95 latency} without inducing oscillation or throttling. To answer this, I built an end-to-end \textbf{ZooKeeper testbed} with Prometheus telemetry, HAProxy traffic shaping, and a constrained library of typed mitigation actions with safety guards, together with a fault-injection and benchmarking harness (\texttt{zkbench}) that supports weighted injections and load-peak scenarios; we run configurations repeatedly to control variance. As a strong baseline, we implemented a \textbf{denoised rule-based baseline} that uses \textbf{sliding-window trend checks} to trigger mitigations and executes parameter-tuned mitigations from a YAML playbook mapping failure modes to actions. While this baseline prevents collapse, it often over- or under-reacts to workload shifts, leaving extended tail-latency windows. I then built an \textbf{agentic layer} where an LLM-based planner reads metrics and finite-state summaries and proposes detailed plans from the same constrained mitigation library; early failures under a richer API (conflicting actions and over-throttling) pushed me to tighten observation/action interfaces. To keep actuation \textbf{safe} under coarse signals and uncertain system state, we treat the LLM as a \textbf{proposal generator} and gate execution with safety bounds and replay-based validation on recent traces. With these guardrails, the agent consistently shortened SLO-violation windows under gray failures~\cite{10.1145/3102980.3103005} and skewed workloads. More broadly, this experience convinced me that in reliability control loops, the bottleneck is rarely ``smarter decisions'' but \textbf{designing the right state abstractions and guardrails} so decisions remain stable under noisy signals. Looking ahead, I hope to expand our failure models to stress more complex scenarios and to improve performance by refining mitigation policies while preserving these guardrails.

\paragraph{CUDA Proxy Player: Runtime Support for Launch-Bound Inference.}
In an Advanced Operating Systems course project, we asked when conditional GPU inference (e.g., Mixture-of-Experts serving) truly becomes \emph{launch-bound}, with host-side orchestration dominating end-to-end latency. Based on the hypothesis that \emph{shape-stable} regions can be amortized while \emph{unstable} glue should be isolated, I co-designed CUDA Proxy Player: a multi-path runtime that routes requests by size and shape to eager, CUDA Graph replay, or persistent-kernel execution, and stitches these flows together via explicit capture/replay and scheduling interfaces. I built the benchmarking framework---microbenchmarks and end-to-end experiments spanning expert sizes, batch shapes, and traffic mixes---to quantify where each path wins and why. In the most launch-bound regimes, size-aware routing enabled the CUDA Graph path to deliver substantial gains over a naïve eager baseline; however, our breakdown also showed why a hybrid graph+worker design often fails to translate into end-to-end wins: coordination overheads (worker scheduling and phase barriers) can dominate, and keeping workers/buffers resident reduces VRAM headroom and can worsen tail latency under multi-tenant workloads. Designing these experiments taught me to separate real speedups from coordination artifacts, and reinforced my view that ML serving runtimes should expose telemetry and control hooks—for VRAM usage, admission control, and path selection---so operators can tune policies to deployment constraints rather than chasing a single ``fastest'' path.

\textbf{Fit with Harvard and Research Environment.}
Harvard’s systems and networking community is an ideal setting for me to pursue reliable AI infrastructure through \textbf{measurement-driven design} and \textbf{end-to-end artifact building}. I see strong alignment with \textbf{Prof.~Juncheng~Yang's} \emph{Helix}\cite{mei2025helixservinglargelanguage} and \textbf{Prof.~Minlan~Yu's} \emph{Confucius}~\cite{10.1145/3718958.3750537}. For Helix, my experience building multi-path GPU runtimes and trace-driven evaluation harnesses positions me to help turn network-aware optimization decisions into \textbf{serving-time mechanisms}—e.g., policies that remain stable under \textbf{KV-cache pressure}, \textbf{GPU heterogeneity}, \textbf{ network heterogeneity and variable network conditions}. For Confucius, my ZooKeeper work on safe agentic mitigation under partial observability directly informs how to design \textbf{constrained action interfaces}: separating proposal from actuation with explicit \textbf{safety budgets and invariants}. Together, these directions provide a concrete path for me to contribute \textbf{reproducible artifacts} and \textbf{safety-constrained control loops} for operating AI datacenters under real-world uncertainty.
%% Summary (3-4 Lines)

% Add some blank space between text and references
% \vspace{0.125in}

% References

% **NOTE**: There are better ways to manage citations in LaTeX, most notably using a bibTeX. I wanted to have greater control on how citations were spaced and formatted and therefore ended up hardcoding them here. Your mileage may wary!
\newpage
\bibliographystyle{abbrv}
\bibliography{paper}

\end{document}

% That's All Folks.

% Best of luck, you got this! :)